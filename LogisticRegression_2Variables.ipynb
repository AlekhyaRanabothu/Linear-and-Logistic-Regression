{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset with 2 variables\n",
    "BSOM_data=pd.read_csv('BSOM_DataSet_for_HW2.csv',usecols = ['all_mcqs_avg_n20','all_NBME_avg_n4','LEVEL'])\n",
    "#checking for missing values\n",
    "BSOM_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the rows with missing values\n",
    "BSOM_data=BSOM_data.dropna(axis=0)\n",
    "BSOM_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the BSOM data with different actual classes\n",
    "def plot_data(BSOM_data):\n",
    "    \n",
    "    x1=BSOM_data[BSOM_data['LEVEL']=='A']\n",
    "    x2=BSOM_data[BSOM_data['LEVEL']=='B']\n",
    "    x3=BSOM_data[BSOM_data['LEVEL']=='C']\n",
    "    x4=BSOM_data[BSOM_data['LEVEL']=='D']\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(x1['all_NBME_avg_n4'],x1['all_mcqs_avg_n20'],c='g',alpha=0.5, marker='o',label=\"A\",s=60)\n",
    "    plt.scatter(x2['all_NBME_avg_n4'],x2['all_mcqs_avg_n20'],c='r',alpha=0.8, marker='x',label=\"B\",s=60)\n",
    "    plt.scatter(x3['all_NBME_avg_n4'],x3['all_mcqs_avg_n20'],c='b',alpha=0.5, marker='v',label=\"C\",s=60)\n",
    "    plt.scatter(x4['all_NBME_avg_n4'],x4['all_mcqs_avg_n20'],c='y',alpha=0.8, marker='s',label=\"D\",s=60)\n",
    "    plt.xlabel(\"NBME_avg\")\n",
    "    plt.ylabel(\"MCQs_avg\")\n",
    "    plt.title(\"LogisticRegression with two variables\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting the BSOM data with actual labels...\")\n",
    "plot_data(BSOM_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the parameters with zeros\n",
    "def initial_parameters(size):\n",
    "    parameters=np.zeros((size,1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the probabilities\n",
    "def hypothesis(X,thetas):\n",
    "    x=np.dot(np.transpose(thetas),X)\n",
    "    h=1 / (1 + np.exp(-x))\n",
    "    zero_matrix=np.zeros(h.shape)\n",
    "    ones_matrix=np.ones(h.shape)\n",
    "    if np.array_equal(h,zero_matrix):\n",
    "        h[h==0.0]=0.00001\n",
    "     \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the cost function\n",
    "def Calc_cost(thetas,X,y):\n",
    "    h=hypothesis(X,thetas)\n",
    "    m=X.shape[1]\n",
    "    J=(-1/(m))*np.sum(y*np.log(h.astype(float))+(1-y)*np.log(1-h.astype(float)))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the gradient descent and updating the parameters\n",
    "def Gradientdescent(X,y,alpha):\n",
    "    m=X.shape[1]\n",
    "    thetas=initial_parameters(X.shape[0])\n",
    "    cost_list=[]\n",
    "    thetas_list=[]\n",
    "    thetas_list.append(thetas)\n",
    "    count=0\n",
    "    final_h=np.zeros(y.shape)\n",
    "    while True:\n",
    "        ypred=hypothesis(X,thetas)\n",
    "        cost=Calc_cost(thetas,X,y)\n",
    "        cost_list.append(cost)\n",
    "        \n",
    "        if (len(cost_list)>=2) and ((cost_list[count-1]-cost_list[count])<0.00001):\n",
    "            print(\"convergence is reached at iteration\",str(count),\"\\n\")\n",
    "            final_h=ypred\n",
    "            break\n",
    "        update_thetas=thetas-(alpha/m)*np.matmul(X,(ypred-y).T)\n",
    "        thetas=update_thetas\n",
    "        count+=1\n",
    "    return thetas,cost_list,count,final_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the labels based on maximum probability among the 4 classifiers\n",
    "def final_prediction(h1,h2,h3,h4):\n",
    "    h1=list(h1)[0]\n",
    "    h2=list(h2)[0]\n",
    "    h3=list(h3)[0]\n",
    "    h4=list(h4)[0]\n",
    "    final_h=[]\n",
    "    max_index=[]\n",
    "    for i in range(0,len(h1)):\n",
    "        temp_list=[]\n",
    "        temp_list.append(h1[i])\n",
    "        temp_list.append(h2[i])\n",
    "        temp_list.append(h3[i])\n",
    "        temp_list.append(h4[i])\n",
    "        max_index.append(temp_list.index(max(temp_list)))\n",
    "        final_h.append(max(temp_list))\n",
    "    return final_h,max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train(70%) and test(30%) datasets\n",
    "features_X = BSOM_data.iloc[:,:-1].to_numpy()\n",
    "y=BSOM_data.iloc[:,-1].to_numpy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(features_X, y, test_size = 0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding bias term to the feature vector and create 4 classifier labels(for each of the 4 classes) in the train and test data sets\n",
    "train_X = Xtrain\n",
    "m_train=train_X.shape[0]\n",
    "train_X=np.append(np.ones((m_train,1)),train_X,axis=1).T\n",
    "train_y=ytrain\n",
    "train_y=pd.get_dummies(train_y).to_numpy()\n",
    "test_X = Xtest\n",
    "m_test=test_X.shape[0]\n",
    "test_X=np.append(np.ones((m_test,1)),test_X,axis=1).T\n",
    "test_y=ytest\n",
    "test_y=pd.get_dummies(test_y).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the class labels in the train data\n",
    "actual_train=ytrain\n",
    "actual_train=np.where(actual_train=='A', 0, actual_train)\n",
    "actual_train=np.where(actual_train=='B', 1, actual_train)\n",
    "actual_train=np.where(actual_train=='C', 2, actual_train)\n",
    "actual_train=np.where(actual_train=='D', 3, actual_train)\n",
    "#encode the class labels in the test data\n",
    "actual_test=ytest\n",
    "actual_test=np.where(actual_test=='A', 0, actual_test)\n",
    "actual_test=np.where(actual_test=='B', 1, actual_test)\n",
    "actual_test=np.where(actual_test=='C', 2, actual_test)\n",
    "actual_test=np.where(actual_test=='D', 3, actual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model using the train dataset for different learning rates\n",
    "\n",
    "alphas_list=[0.1,0.5,0.6,0.7]\n",
    "\n",
    "for i in alphas_list:\n",
    "    print(\"learning_rate :\\n\",str(i))\n",
    "    print(\"classifier 1(class A vs not class A)\")\n",
    "    coef1,costs_J1,num_iter1,train_pred1=Gradientdescent(train_X,train_y[:,0],i)\n",
    "    \n",
    "    print(\"classifier 2(class B vs not class B)\")\n",
    "    coef2,costs_J2,num_iter2,train_pred2=Gradientdescent(train_X,train_y[:,1],i)\n",
    "\n",
    "    \n",
    "    print(\"classifier 3(class C vs not class C)\")\n",
    "    coef3,costs_J3,num_iter3,train_pred3=Gradientdescent(train_X,train_y[:,2],i)\n",
    "    \n",
    "    print(\"classifier 4(class D vs not class D)\")\n",
    "    coef4,costs_J4,num_iter4,train_pred4=Gradientdescent(train_X,train_y[:,3],i)\n",
    "\n",
    "    fh,labels=final_prediction(train_pred1,train_pred2,train_pred3,train_pred4)\n",
    "    final_labels=np.array(labels)\n",
    "    print(\"Confusion Matrix \\n\")\n",
    "    cf=confusion_matrix(list(actual_train),list(final_labels))\n",
    "    print(cf)\n",
    "    pr=precision_score(list(actual_train),list(final_labels),average='macro')\n",
    "    rc=recall_score(list(actual_train),list(final_labels),average='macro')\n",
    "    f1=f1_score(list(actual_train),list(final_labels),average='macro')\n",
    "    print(\"Precision : \",str(pr))\n",
    "    print(\"Recall : \",str(rc))\n",
    "    print(\"F1 score : \",str(f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costfunction(iter_num,J_list,classname):\n",
    "    #plotting the cost (vs) iterations graph\n",
    "    iterations=list(np.arange(0,iter_num,1))\n",
    "    cost_J=[]\n",
    "    for i in iterations:\n",
    "        cost_J.append(J_list[i])\n",
    "\n",
    "    plt.plot(iterations,cost_J)\n",
    "    plt.xlabel(\"#Iterations\")\n",
    "    plt.ylabel(\"J (cost)\")\n",
    "    plt.title(\"Logistic Regression class \"+str(classname)+\" vs not class \"+str(classname))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cf_matrix):\n",
    "    sns.heatmap(cf,xticklabels=['A','B','C','D'],yticklabels=['A','B','C','D'],annot=True,linecolor='white',linewidths=0.5,cmap='coolwarm')\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"actual labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##best parameters with best alpha on training data set\n",
    "best_alpha=0.6\n",
    "print(\"classifier 1(class A vs not class A)\\n\")\n",
    "best_coef1,costs_J1,num_iter1,best_train_pred1=Gradientdescent(train_X,train_y[:,0],best_alpha)\n",
    "print(\"classifier 2(class B vs not class B)\\n\")\n",
    "best_coef2,costs_J2,num_iter2,best_train_pred2=Gradientdescent(train_X,train_y[:,1],best_alpha)\n",
    "print(\"classifier 3(class C vs not class C)\\n\")\n",
    "best_coef3,costs_J3,num_iter3,best_train_pred3=Gradientdescent(train_X,train_y[:,2],best_alpha)\n",
    "print(\"classifier 4(class D vs not class D)\\n\")\n",
    "best_coef4,costs_J4,num_iter4,best_train_pred4=Gradientdescent(train_X,train_y[:,3],best_alpha)\n",
    "best_pred,best_labels=final_prediction(best_train_pred1,best_train_pred2,best_train_pred3,best_train_pred4)\n",
    "final_labels_train=np.array(best_labels)\n",
    "print(\"Confusion Matrix \\n\")\n",
    "cf=confusion_matrix(list(actual_train),list(final_labels_train))\n",
    "print(cf)\n",
    "\n",
    "pr=precision_score(list(actual_train),list(final_labels_train),average='macro')\n",
    "rc=recall_score(list(actual_train),list(final_labels_train),average='macro')\n",
    "f1=f1_score(list(actual_train),list(final_labels_train),average='macro')\n",
    "print(\"Precision : \",str(pr))\n",
    "print(\"Recall : \",str(rc))\n",
    "print(\"F1 score : \",str(f1))\n",
    "\n",
    "#plot the cost function for all the classifiers\n",
    "plot_costfunction(num_iter1,costs_J1,'A')\n",
    "plot_costfunction(num_iter2,costs_J2,'B')\n",
    "plot_costfunction(num_iter3,costs_J3,'C')\n",
    "plot_costfunction(num_iter4,costs_J4,'D')\n",
    "print(\"confusion matrix of training data\")\n",
    "plot_confusion_matrix(cf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on test data with best alpha and best parameters\n",
    "\n",
    "test_pred1=hypothesis(test_X,best_coef1)\n",
    "test_pred2=hypothesis(test_X,best_coef2)\n",
    "test_pred3=hypothesis(test_X,best_coef3)\n",
    "test_pred4=hypothesis(test_X,best_coef4)\n",
    "pred_test,labels_test=final_prediction(test_pred1,test_pred2,test_pred3,test_pred4)\n",
    "final_labels_test=np.array(labels_test)\n",
    "print(\"Confusion Matrix of test data\\n\")\n",
    "cf=confusion_matrix(list(actual_test),list(final_labels_test))\n",
    "print(cf)\n",
    "plot_confusion_matrix(cf)\n",
    "pr=precision_score(list(actual_test),list(final_labels_test),average='macro')\n",
    "rc=recall_score(list(actual_test),list(final_labels_test),average='macro')\n",
    "f1=f1_score(list(actual_test),list(final_labels_test),average='macro')\n",
    "print(\"Precision : \",str(pr))\n",
    "print(\"Recall : \",str(rc))\n",
    "print(\"F1 score : \",str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the BSOM data with different classes\n",
    "def plot_predicteddata(predict_data,name):\n",
    "    \n",
    "    x1=predict_data[predict_data['predicted_labels']==0]\n",
    "    x2=predict_data[predict_data['predicted_labels']==1]\n",
    "    x3=predict_data[predict_data['predicted_labels']==2]\n",
    "    x4=predict_data[predict_data['predicted_labels']==3]\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(x1['x1'],x1['x2'],c='g',alpha=0.5, marker='o',label=\"A\",s=60)\n",
    "    plt.scatter(x2['x1'],x2['x2'],c='r',alpha=0.8, marker='x',label=\"B\",s=60)\n",
    "    plt.scatter(x3['x1'],x3['x2'],c='b',alpha=0.5, marker='v',label=\"C\",s=60)\n",
    "    plt.scatter(x4['x1'],x4['x2'],c='y',alpha=0.8, marker='s',label=\"D\",s=60)\n",
    "    plt.xlabel(\"NBME_avg\")\n",
    "    plt.ylabel(\"MCQs_avg\")\n",
    "    plt.title(\"LogisticRegression prediction on \"+str(name))\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the predicted classes for train data and test data sets\n",
    "d_train = {'x1':list(Xtrain[:,0]), 'x2':list(Xtrain[:,1]),'predicted_labels':final_labels_train }\n",
    "\n",
    "d_test = {'x1':list(Xtest[:,0]), 'x2':list(Xtest[:,1]),'predicted_labels':final_labels_test }\n",
    "traindata_predict=pd.DataFrame(data=d_train)\n",
    "testdata_predict=pd.DataFrame(data=d_test)\n",
    "predicted_data=traindata_predict.append(testdata_predict)\n",
    "\n",
    "plot_predicteddata(traindata_predict,'training data')\n",
    "\n",
    "plot_predicteddata(testdata_predict,'test data')\n",
    "\n",
    "plot_predicteddata(predicted_data,'complete data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
